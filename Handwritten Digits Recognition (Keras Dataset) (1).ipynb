{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Handwritten Digits Recognition (Keras Dataset).ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"G3jbYViIVIyx","colab_type":"text"},"cell_type":"markdown","source":["Managing imports"]},{"metadata":{"id":"R0tvkXQG8gH3","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XeeGDnyEVYtp","colab_type":"text"},"cell_type":"markdown","source":["Loading the MNIST Dataset"]},{"metadata":{"id":"iUXDMm86VZB5","colab_type":"code","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pTKHzh4TVnGx","colab_type":"text"},"cell_type":"markdown","source":["Reshaping the data to the form (batch, height, width, channels) form.\n","Here, channels = 1 as the image is in greyscale. Had it been colour, we would have set it to '3'."]},{"metadata":{"id":"E4UAcraUWQPg","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_oT_72yhWRQv","colab_type":"text"},"cell_type":"markdown","source":["Normalizing the pixel values from range 0-255 to range 0-1"]},{"metadata":{"id":"p79krs-7WZx_","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train/255\n","X_test = X_test/255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gbRziipHWd_A","colab_type":"text"},"cell_type":"markdown","source":["Since this is a multi-class classification problem with 10 classes, we will be using one-hot encoding for each class.\n","For example, the output for class 0 will be [1, 0, 0, 0, 0, 0, 0, 0, 0,]."]},{"metadata":{"id":"ZupMnPrCW-MR","colab_type":"code","colab":{}},"cell_type":"code","source":["number = 10\n","y_train = np_utils.to_categorical(y_train, number)\n","y_test = np_utils.to_categorical(y_test, number)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_CwXbpiTW_FY","colab_type":"text"},"cell_type":"markdown","source":["Now, we will be defining our model.\n","\n","*(As our dataset contains images, we will be using Conv2D and MaxPooling2D functions)*\n","\n","1.   Convolution layer with 1024 filters, each with size 5X5, and activation function 'relu'. The expected input shape also needs to be passed as an argument since this is the first hidden layer.\n","2.   Max Pooling layer. Max Pooling layer is used to down-sample the input to enable the model to make assumptions about the features so as to reduce over-fitting. It also reduces the number of parameters to learn, reducing the training time.\n","3. One more convolution layer with 512 filters, each with size 4X4, and activation function 'relu'.\n","4. One more Max Pooling layer.\n","5.  Another final convolution layer with 256 filters, each with size 3X3, and activation function 'relu'.\n","6. Final Max Pooling layer.\n","7. The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 30% of neurons in the layer in order to reduce overfitting.\n","8. Next layer converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n","9. Next layer is a fully connected layer with 128 neurons.\n","10. Next layer is another fully connected layer with 64 neurons.\n","11. The last layer is output layer with 10 neurons(number of output classes) and it uses softmax activation function. Each neuron will give the probability of that class. Itâ€™s a multi-class classification problem, that is why softmax activation function is used. Had it been a binary classification problem, we would have used sigmoid activation function.\n"]},{"metadata":{"id":"k51W79wQXJJ5","colab_type":"code","colab":{}},"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(1024, (5, 5), input_shape = (X_train.shape[1], X_train.shape[2], 1), activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(512, (4, 4), activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Conv2D(256, (3, 3), activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(64, activation = 'relu'))\n","model.add(Dense(number, activation = 'softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6y8oRS7OYyyJ","colab_type":"text"},"cell_type":"markdown","source":["Now, we will be looking at the summary of our model."]},{"metadata":{"id":"4Vsj-3laYyTZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":502},"outputId":"26fef839-742d-4ee7-a935-acba0db14bbf","executionInfo":{"status":"ok","timestamp":1553325899384,"user_tz":-330,"elapsed":1836,"user":{"displayName":"Souparno Bhattacharyya","photoUrl":"https://lh6.googleusercontent.com/-kfWdU681MlY/AAAAAAAAAAI/AAAAAAAAADI/pWqM0EMHz3w/s64/photo.jpg","userId":"14221323236468370120"}}},"cell_type":"code","source":["model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 24, 24, 1024)      26624     \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 12, 12, 1024)      0         \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 9, 9, 512)         8389120   \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 2, 2, 256)         1179904   \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 1, 1, 256)         0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 1, 1, 256)         0         \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 256)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 10)                650       \n","=================================================================\n","Total params: 9,637,450\n","Trainable params: 9,637,450\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"r--1LkayY94h","colab_type":"text"},"cell_type":"markdown","source":["Next, we will be compiling our model using categorical cross-entropy as a loss function as it is a multi-class classification problem.\n","\n","Adam optimizer is used to ensure that the weights are optimized properly. I have tried other optimizers as well, but Adam gives the best results.\n","\n","Accuracy will be the metric based on which the performance of our neural network will be improved."]},{"metadata":{"id":"uHqd3ZlAY_4h","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gTkmFk9tZZ0Z","colab_type":"text"},"cell_type":"markdown","source":["Now, we will be training our model.\n","\n","The model is going to fit over 10 epochs and is going to update after every 50 images training. \n","\n","The test data is used as the validation dataset."]},{"metadata":{"id":"qDR-Uvv7Zdk6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":385},"outputId":"da26953f-1173-4e93-c18b-03c5e57136ce","executionInfo":{"status":"ok","timestamp":1553327796928,"user_tz":-330,"elapsed":1891125,"user":{"displayName":"Souparno Bhattacharyya","photoUrl":"https://lh6.googleusercontent.com/-kfWdU681MlY/AAAAAAAAAAI/AAAAAAAAADI/pWqM0EMHz3w/s64/photo.jpg","userId":"14221323236468370120"}}},"cell_type":"code","source":["model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=50)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 193s 3ms/step - loss: 0.1749 - acc: 0.9453 - val_loss: 0.0324 - val_acc: 0.9902\n","Epoch 2/10\n","60000/60000 [==============================] - 191s 3ms/step - loss: 0.0554 - acc: 0.9842 - val_loss: 0.0279 - val_acc: 0.9920\n","Epoch 3/10\n","60000/60000 [==============================] - 190s 3ms/step - loss: 0.0407 - acc: 0.9882 - val_loss: 0.0323 - val_acc: 0.9909\n","Epoch 4/10\n","60000/60000 [==============================] - 189s 3ms/step - loss: 0.0327 - acc: 0.9908 - val_loss: 0.0362 - val_acc: 0.9912\n","Epoch 5/10\n","60000/60000 [==============================] - 188s 3ms/step - loss: 0.0283 - acc: 0.9922 - val_loss: 0.0364 - val_acc: 0.9913\n","Epoch 6/10\n","60000/60000 [==============================] - 188s 3ms/step - loss: 0.0247 - acc: 0.9929 - val_loss: 0.0225 - val_acc: 0.9938\n","Epoch 7/10\n","60000/60000 [==============================] - 188s 3ms/step - loss: 0.0195 - acc: 0.9946 - val_loss: 0.0248 - val_acc: 0.9935\n","Epoch 8/10\n","60000/60000 [==============================] - 188s 3ms/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.0307 - val_acc: 0.9932\n","Epoch 9/10\n","60000/60000 [==============================] - 187s 3ms/step - loss: 0.0162 - acc: 0.9954 - val_loss: 0.0297 - val_acc: 0.9941\n","Epoch 10/10\n","60000/60000 [==============================] - 187s 3ms/step - loss: 0.0156 - acc: 0.9959 - val_loss: 0.0220 - val_acc: 0.9946\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2276daa240>"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"ICUEgfZgbiiC","colab_type":"text"},"cell_type":"markdown","source":["Now, we will be compiling and running our model and check the training loss and accuracy as well as the test loss and accuracy."]},{"metadata":{"id":"uxNsEX06bnmi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"b38f8726-629b-4e02-b5de-ea835a98cfb3","executionInfo":{"status":"ok","timestamp":1553328286197,"user_tz":-330,"elapsed":76707,"user":{"displayName":"Souparno Bhattacharyya","photoUrl":"https://lh6.googleusercontent.com/-kfWdU681MlY/AAAAAAAAAAI/AAAAAAAAADI/pWqM0EMHz3w/s64/photo.jpg","userId":"14221323236468370120"}}},"cell_type":"code","source":["metrics_train = model.evaluate(X_train, y_train, verbose=0)\n","print(\"Metrics(Train loss & Train Accuracy): \")\n","print(metrics_train)\n","\n","metrics_test = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Metrics(Test loss & Test Accuracy): \")\n","print(metrics_test)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Metrics(Train loss & Train Accuracy): \n","[0.005230440739199806, 0.9985833333333334]\n","Metrics(Test loss & Test Accuracy): \n","[0.022045926705585042, 0.9946]\n"],"name":"stdout"}]}]}